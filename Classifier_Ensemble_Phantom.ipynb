{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smomtahe/ensemble-learning-absorption/blob/main/Classifier_Ensemble_Phantom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can use github\n",
        "%pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "id": "mvo7YCorpNfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72dc072d-349b-474e-8418-70ecb2f7808b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-y688ubtu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-y688ubtu\n",
            "  Resolved https://github.com/tensorflow/docs to commit 3b8eeeeddb85f606812874d2aa45823227afc6bf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.7.13.64986) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.7.13.64986) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.7.13.64986) (3.1.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.7.13.64986) (5.9.1)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.7.13.64986) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.7.13.64986) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2023.7.13.64986) (2.1.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.7.13.64986) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.7.13.64986) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.7.13.64986) (5.3.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.7.13.64986) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.7.13.64986) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.7.13.64986) (0.19.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==2023.7.13.64986) (3.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PbtCOBgKU1xU"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import numpy as np # for math and arrays\n",
        "import pandas as pd # data from for the data.\n",
        "import seaborn as sns # for plotting.\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# for plotting\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt # for plotting data and creating different charts.\n",
        "\n",
        "# for the operating system operations e.g., creating a folder.\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "%matplotlib inline\n",
        "# Tensorflow and Keras are two packages for creating neural network models.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# import NN layers and other componenets.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Tensorflow untils packages.\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "import pathlib # for processing a path e.g., c:\\documents\\files\\test_ds.csv\n",
        "\n",
        "#upload data from my github\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/smomtahe/ai/main/DL_LP_new_new.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "X = data['minR1R2'].values\n",
        "X = X.reshape((-1, 1))\n",
        "x = X[17:]\n",
        "Y = data['a690'].values\n",
        "y = Y[17:]\n",
        "#15 -> %25\n",
        "x_test = X[:17]\n",
        "y_test=Y[:17]\n",
        "y_test=y_test.reshape((-1, 1))"
      ],
      "metadata": {
        "id": "ZxGfisibqsKk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fec0bbde-b488-417d-b8b3-cda98d1ab406"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to normalize the data set\n",
        "def norm(x):\n",
        "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
        "x = norm(x)\n",
        "y = norm(y)\n",
        "x_test = norm(x_test)\n",
        "y_test = norm(y_test)\n"
      ],
      "metadata": {
        "id": "IBJhtierL955"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install boosting\n",
        "!pip install catboost\n",
        "!pip install xgboost\n",
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhjAJw44HtLQ",
        "outputId": "a11540df-7419-4c18-9bd3-e74ea8bd8d6a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (3.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define base estimators\n",
        "base1 = SVR(kernel='rbf')\n",
        "base2 = RandomForestRegressor(n_estimators=100, max_depth=10, max_features='sqrt', random_state=42)\n",
        "base3 = KNeighborsRegressor(n_neighbors=3)\n",
        "base4 = DecisionTreeRegressor(max_depth=5)\n",
        "base5 = MLPRegressor(hidden_layer_sizes=(64, 32,16), activation='relu', solver='adam', max_iter=1000, alpha=0.1)\n",
        "base6 = make_pipeline(PolynomialFeatures(degree=4), KNeighborsRegressor())\n",
        "base7 = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "base8 = CatBoostRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42, verbose=0)\n",
        "base9 = ExtraTreesRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "\n",
        "# Define ensemble models\n",
        "ensemble1 = BaggingRegressor(base_estimator=base1, n_estimators=10, random_state=42)\n",
        "ensemble2 = AdaBoostRegressor(base_estimator=base2, n_estimators=10, random_state=42)\n",
        "ensemble3 = BaggingRegressor(base_estimator=base3, n_estimators=10, random_state=42)\n",
        "ensemble4 = AdaBoostRegressor(base_estimator=base4, n_estimators=10, random_state=42)\n",
        "ensemble5 = BaggingRegressor(base_estimator=base5, n_estimators=10, random_state=42)\n",
        "ensemble6 = AdaBoostRegressor(base_estimator=base6, n_estimators=10, random_state=42)\n",
        "ensemble7 = GradientBoostingRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "ensemble8 = VotingRegressor([('svr', base1), ('rf', base2), ('knn', base3), ('dt', base4), ('mlp', base5), ('polyknn', base6), ('xgb', base7), ('catboost', base8)])\n",
        "ensemble9 = BaggingRegressor(base_estimator=base9, n_estimators=10, random_state=42)\n",
        "\n",
        "# Fit models on training data\n",
        "ensemble1.fit(x, y)\n",
        "ensemble2.fit(x, y)\n",
        "ensemble3.fit(x, y)\n",
        "ensemble4.fit(x, y)\n",
        "ensemble5.fit(x, y)\n",
        "ensemble6.fit(x, y)\n",
        "ensemble7.fit(x, y)\n",
        "ensemble8.fit(x, y)\n",
        "ensemble9.fit(x, y)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred1 = ensemble1.predict(x_test)\n",
        "y_pred2 = ensemble2.predict(x_test)\n",
        "y_pred3 = ensemble3.predict(x_test)\n",
        "y_pred4 = ensemble4.predict(x_test)\n",
        "y_pred5 = ensemble5.predict(x_test)\n",
        "y_pred6 = ensemble6.predict(x_test)\n",
        "y_pred7 = ensemble7.predict(x_test)\n",
        "y_pred8 = ensemble8.predict(x_test)\n",
        "y_pred9 = ensemble9.predict(x_test)\n",
        "\n",
        "# Compute mean squared error\n",
        "mse1 = mean_squared_error(y_test, y_pred1)\n",
        "mse2 = mean_squared_error(y_test, y_pred2)\n",
        "mse3 = mean_squared_error(y_test, y_pred3)\n",
        "mse4 = mean_squared_error(y_test, y_pred4)\n",
        "mse5 = mean_squared_error(y_test, y_pred5)\n",
        "mse6 = mean_squared_error(y_test, y_pred6)\n",
        "mse7 = mean_squared_error(y_test, y_pred7)\n",
        "mse8 = mean_squared_error(y_test, y_pred8)\n",
        "mse9 = mean_squared_error(y_test, y_pred9)\n",
        "\n",
        "print(\"MSE for ensemble 1:\", mse1)\n",
        "print(\"MSE for ensemble 2:\", mse2)\n",
        "print(\"MSE for ensemble 3:\", mse3)\n",
        "print(\"MSE for ensemble 4:\", mse4)\n",
        "print(\"MSE for ensemble 5:\", mse5)\n",
        "print(\"MSE for ensemble 6:\", mse6)\n",
        "print(\"MSE for ensemble 7:\", mse7)\n",
        "print(\"MSE for ensemble 8:\", mse8)\n",
        "print(\"MSE for ensemble 9:\", mse9)\n",
        "\n",
        "r2_1 = r2_score(y_test, y_pred1)\n",
        "r2_2 = r2_score(y_test, y_pred2)\n",
        "r2_3 = r2_score(y_test, y_pred3)\n",
        "r2_4 = r2_score(y_test, y_pred4)\n",
        "r2_5 = r2_score(y_test, y_pred5)\n",
        "r2_6 = r2_score(y_test, y_pred6)\n",
        "r2_7 = r2_score(y_test, y_pred7)\n",
        "r2_8 = r2_score(y_test, y_pred8)\n",
        "r2_9 = r2_score(y_test, y_pred9)\n",
        "\n",
        "# Print results\n",
        "print('Bagging ensemble with SVR R-squared score: %.2f' % r2_1)\n",
        "print('Boosting ensemble with Random Forest Regressor R-squared score: %.2f' % r2_2)\n",
        "print('Bagging ensemble with KNN Regressor R-squared score: %.2f' % r2_3)\n",
        "print('Boosting ensemble with Decision Tree Regressor R-squared score: %.2f' % r2_4)\n",
        "print('Bagging ensemble with MLP RegressorR-squared score: %.2f' % r2_5)\n",
        "print('Boosting ensemble with Polynomial Regressor R-squared score: %.2f' % r2_6)\n",
        "print('Bagging ensemble with CatBoostRegressor R-squared score: %.2f' % r2_7)\n",
        "print('Boosting ensemble with XGBRegressor R-squared score: %.2f' % r2_8)\n",
        "print('Bagging ensemble with Extra Trees Regressor R-squared score: %.2f' % r2_9)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvJULSkxHIOT",
        "outputId": "c8ffb068-30ae-43f4-d4c8-b02897ad0432"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for ensemble 1: 0.015389559242600204\n",
            "MSE for ensemble 2: 0.017585991406999214\n",
            "MSE for ensemble 3: 0.008881337861692934\n",
            "MSE for ensemble 4: 0.026292446213939554\n",
            "MSE for ensemble 5: 0.01737986752054931\n",
            "MSE for ensemble 6: 0.01111137996304502\n",
            "MSE for ensemble 7: 0.02821433292132878\n",
            "MSE for ensemble 8: 0.009392141216899906\n",
            "MSE for ensemble 9: 0.007989050727191024\n",
            "Bagging ensemble with SVR R-squared score: 0.86\n",
            "Boosting ensemble with Random Forest Regressor R-squared score: 0.84\n",
            "Bagging ensemble with KNN Regressor R-squared score: 0.92\n",
            "Boosting ensemble with Decision Tree Regressor R-squared score: 0.75\n",
            "Bagging ensemble with MLP RegressorR-squared score: 0.84\n",
            "Boosting ensemble with Polynomial Regressor R-squared score: 0.90\n",
            "Bagging ensemble with CatBoostRegressor R-squared score: 0.74\n",
            "Boosting ensemble with XGBRegressor R-squared score: 0.91\n",
            "Bagging ensemble with Extra Trees Regressor R-squared score: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_ensemble1 = norm(y_pred1)\n",
        "y_ensemble2 = norm(y_pred2)\n",
        "y_ensemble3 = norm(y_pred3)\n",
        "y_ensemble4 = norm(y_pred4)\n",
        "y_ensemble5 = norm(y_pred5)\n",
        "y_ensemble6 = norm(y_pred6)\n",
        "y_ensemble7 = norm(y_pred7)\n",
        "y_ensemble8 = norm(y_pred8)\n",
        "y_ensemble9 = norm(y_pred9)"
      ],
      "metadata": {
        "id": "YftcJk0BVHuH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make class predictions with 4 best models\n",
        "predictions3 = (y_ensemble3 > 0.55).astype(int)\n",
        "print(*predictions3)\n",
        "predictions6 = (y_ensemble6 > 0.55).astype(int)\n",
        "print(*predictions6)\n",
        "predictions8 = (y_ensemble8 > 0.55).astype(int)\n",
        "print(*predictions8)\n",
        "predictions9 = (y_ensemble9 > 0.55).astype(int)\n",
        "print(*predictions9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emzZf4LfU9w3",
        "outputId": "69644ba7-de21-40b2-ad6c-c95825cad7f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
            "0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0\n",
            "0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0\n",
            "0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_type= (y_test > 0.5).astype(int)\n",
        "print(*y_test_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn0sQddO-uOv",
        "outputId": "43991f93-1a79-471b-cc28-ef851de84c86"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] [0] [0] [0] [1] [1] [1] [1] [0] [0] [0] [0] [1] [1] [1] [1] [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test_type,predictions3))\n",
        "\n",
        "import sklearn.metrics\n",
        "import math\n",
        "def matrix_metrix(y_test,test_predictions,beta):\n",
        "   CM = confusion_matrix(y_test_type,predictions3)\n",
        "   TN = CM[0][0]\n",
        "   FN = CM[1][0]\n",
        "   TP = CM[1][1]\n",
        "   FP = CM[0][1]\n",
        "   MSE = mean_squared_error(y_test_type,predictions3)\n",
        "   RMSE = np.sqrt(mean_squared_error(y_test_type,predictions3))\n",
        "   Population = TN+FN+TP+FP\n",
        "   Prevalence = round( (TP+FP) / Population,2)\n",
        "   Accuracy   = round( (TP+TN) / Population,4)\n",
        "   Sensitivity   = ( TP / (TP+FN))\n",
        "   Specificity   = ( TN / (TN+FP))\n",
        "   Precision  = round( TP / (TP+FP),4 )\n",
        "   NPV        = round( TN / (TN+FN),4 )\n",
        "   FDR        = round( FP / (TP+FP),4 )\n",
        "   FOR        = round( FN / (TN+FN),4 )\n",
        "   check_Pos  = Precision + FDR\n",
        "   check_Neg  = NPV + FOR\n",
        "   Recall     = round( TP / (TP+FN),4 )\n",
        "   FPR        = round( FP / (TN+FP),4 )\n",
        "   FNR        = round( FN / (TP+FN),4 )\n",
        "   TNR        = round( TN / (TN+FP),4 )\n",
        "   check_Pos2 = Recall + FNR\n",
        "   check_Neg2 = FPR + TNR\n",
        "   LRPos      = round( Recall/FPR,4 )\n",
        "   LRNeg      = round( FNR / TNR ,4 )\n",
        "   F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)\n",
        "   FBeta      = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)\n",
        "   MCC        = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)\n",
        "   BM         = Recall+TNR-1\n",
        "   MK         = Precision+NPV-1\n",
        "   mat_met = pd.DataFrame({\n",
        "'Metric':['TP','TN','FP','FN','MSE','RMSE','Prevalence','Accuracy','Sensitivity','Specificity','Precision','NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','F1','FBeta','MCC','BM','MK'],     'Value':[TP,TN,FP,FN,MSE,RMSE,Prevalence,Accuracy,Sensitivity,Specificity,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,F1,FBeta,MCC,BM,MK]})\n",
        "   return (mat_met)\n",
        "beta = 0.4\n",
        "mat_met = matrix_metrix(y_test_type,predictions3,beta)\n",
        "print (mat_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_JdJVdRVQm_",
        "outputId": "0c8125a9-bd25-4f32-8280-6646c18bc1c8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9 0]\n",
            " [0 8]]\n",
            "         Metric  Value\n",
            "0            TP   8.00\n",
            "1            TN   9.00\n",
            "2            FP   0.00\n",
            "3            FN   0.00\n",
            "4           MSE   0.00\n",
            "5          RMSE   0.00\n",
            "6    Prevalence   0.47\n",
            "7      Accuracy   1.00\n",
            "8   Sensitivity   1.00\n",
            "9   Specificity   1.00\n",
            "10    Precision   1.00\n",
            "11          NPV   1.00\n",
            "12          FDR   0.00\n",
            "13          FOR   0.00\n",
            "14    check_Pos   1.00\n",
            "15    check_Neg   1.00\n",
            "16       Recall   1.00\n",
            "17          FPR   0.00\n",
            "18          FNR   0.00\n",
            "19          TNR   1.00\n",
            "20   check_Pos2   1.00\n",
            "21   check_Neg2   1.00\n",
            "22          LR+    inf\n",
            "23          LR-   0.00\n",
            "24           F1   1.00\n",
            "25        FBeta   1.00\n",
            "26          MCC   1.00\n",
            "27           BM   1.00\n",
            "28           MK   1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-400ac560c3c3>:31: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  LRPos      = round( Recall/FPR,4 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test_type,predictions6))\n",
        "\n",
        "import sklearn.metrics\n",
        "import math\n",
        "def matrix_metrix(y_test,test_predictions,beta):\n",
        "   CM = confusion_matrix(y_test_type,predictions6)\n",
        "   TN = CM[0][0]\n",
        "   FN = CM[1][0]\n",
        "   TP = CM[1][1]\n",
        "   FP = CM[0][1]\n",
        "   MSE = mean_squared_error(y_test_type,predictions6)\n",
        "   RMSE = np.sqrt(mean_squared_error(y_test_type,predictions6))\n",
        "   Population = TN+FN+TP+FP\n",
        "   Prevalence = round( (TP+FP) / Population,2)\n",
        "   Accuracy   = round( (TP+TN) / Population,4)\n",
        "   Sensitivity   = ( TP / (TP+FN))\n",
        "   Specificity   = ( TN / (TN+FP))\n",
        "   Precision  = round( TP / (TP+FP),4 )\n",
        "   NPV        = round( TN / (TN+FN),4 )\n",
        "   FDR        = round( FP / (TP+FP),4 )\n",
        "   FOR        = round( FN / (TN+FN),4 )\n",
        "   check_Pos  = Precision + FDR\n",
        "   check_Neg  = NPV + FOR\n",
        "   Recall     = round( TP / (TP+FN),4 )\n",
        "   FPR        = round( FP / (TN+FP),4 )\n",
        "   FNR        = round( FN / (TP+FN),4 )\n",
        "   TNR        = round( TN / (TN+FP),4 )\n",
        "   check_Pos2 = Recall + FNR\n",
        "   check_Neg2 = FPR + TNR\n",
        "   LRPos      = round( Recall/FPR,4 )\n",
        "   LRNeg      = round( FNR / TNR ,4 )\n",
        "   F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)\n",
        "   FBeta      = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)\n",
        "   MCC        = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)\n",
        "   BM         = Recall+TNR-1\n",
        "   MK         = Precision+NPV-1\n",
        "   mat_met = pd.DataFrame({\n",
        "'Metric':['TP','TN','FP','FN','MSE','RMSE','Prevalence','Accuracy','Sensitivity','Specificity','Precision','NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','F1','FBeta','MCC','BM','MK'],     'Value':[TP,TN,FP,FN,MSE,RMSE,Prevalence,Accuracy,Sensitivity,Specificity,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,F1,FBeta,MCC,BM,MK]})\n",
        "   return (mat_met)\n",
        "beta = 0.4\n",
        "mat_met = matrix_metrix(y_test_type,predictions6,beta)\n",
        "y_test_type = (y_test > 0.5).astype(int)\n",
        "print(*y_test_type)\n",
        "print (mat_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQtOqHIO-bgC",
        "outputId": "82297224-ed7c-443b-c050-e5599387960c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9 0]\n",
            " [1 7]]\n",
            "[0] [0] [0] [0] [1] [1] [1] [1] [0] [0] [0] [0] [1] [1] [1] [1] [0]\n",
            "         Metric     Value\n",
            "0            TP  7.000000\n",
            "1            TN  9.000000\n",
            "2            FP  0.000000\n",
            "3            FN  1.000000\n",
            "4           MSE  0.058824\n",
            "5          RMSE  0.242536\n",
            "6    Prevalence  0.410000\n",
            "7      Accuracy  0.941200\n",
            "8   Sensitivity  0.875000\n",
            "9   Specificity  1.000000\n",
            "10    Precision  1.000000\n",
            "11          NPV  0.900000\n",
            "12          FDR  0.000000\n",
            "13          FOR  0.100000\n",
            "14    check_Pos  1.000000\n",
            "15    check_Neg  1.000000\n",
            "16       Recall  0.875000\n",
            "17          FPR  0.000000\n",
            "18          FNR  0.125000\n",
            "19          TNR  1.000000\n",
            "20   check_Pos2  1.000000\n",
            "21   check_Neg2  1.000000\n",
            "22          LR+       inf\n",
            "23          LR-  0.125000\n",
            "24           F1  0.933300\n",
            "25        FBeta  0.980700\n",
            "26          MCC  0.887400\n",
            "27           BM  0.875000\n",
            "28           MK  0.900000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-76ff4b9311fd>:31: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  LRPos      = round( Recall/FPR,4 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test_type,predictions8))\n",
        "\n",
        "import sklearn.metrics\n",
        "import math\n",
        "def matrix_metrix(y_test,test_predictions,beta):\n",
        "   CM = confusion_matrix(y_test_type,predictions8)\n",
        "   TN = CM[0][0]\n",
        "   FN = CM[1][0]\n",
        "   TP = CM[1][1]\n",
        "   FP = CM[0][1]\n",
        "   MSE = mean_squared_error(y_test_type,predictions8)\n",
        "   RMSE = np.sqrt(mean_squared_error(y_test_type,predictions8))\n",
        "   Population = TN+FN+TP+FP\n",
        "   Prevalence = round( (TP+FP) / Population,2)\n",
        "   Accuracy   = round( (TP+TN) / Population,4)\n",
        "   Sensitivity   = ( TP / (TP+FN))\n",
        "   Specificity   = ( TN / (TN+FP))\n",
        "   Precision  = round( TP / (TP+FP),4 )\n",
        "   NPV        = round( TN / (TN+FN),4 )\n",
        "   FDR        = round( FP / (TP+FP),4 )\n",
        "   FOR        = round( FN / (TN+FN),4 )\n",
        "   check_Pos  = Precision + FDR\n",
        "   check_Neg  = NPV + FOR\n",
        "   Recall     = round( TP / (TP+FN),4 )\n",
        "   FPR        = round( FP / (TN+FP),4 )\n",
        "   FNR        = round( FN / (TP+FN),4 )\n",
        "   TNR        = round( TN / (TN+FP),4 )\n",
        "   check_Pos2 = Recall + FNR\n",
        "   check_Neg2 = FPR + TNR\n",
        "   LRPos      = round( Recall/FPR,4 )\n",
        "   LRNeg      = round( FNR / TNR ,4 )\n",
        "   F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)\n",
        "   FBeta      = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)\n",
        "   MCC        = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)\n",
        "   BM         = Recall+TNR-1\n",
        "   MK         = Precision+NPV-1\n",
        "   mat_met = pd.DataFrame({\n",
        "'Metric':['TP','TN','FP','FN','MSE','RMSE','Prevalence','Accuracy','Sensitivity','Specificity','Precision','NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','F1','FBeta','MCC','BM','MK'],     'Value':[TP,TN,FP,FN,MSE,RMSE,Prevalence,Accuracy,Sensitivity,Specificity,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,F1,FBeta,MCC,BM,MK]})\n",
        "   return (mat_met)\n",
        "beta = 0.4\n",
        "mat_met = matrix_metrix(y_test_type,predictions8,beta)\n",
        "y_test_type = (y_test > 0.5).astype(int)\n",
        "print(*y_test_type)\n",
        "print (mat_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oo4gGWfIyC0",
        "outputId": "edcb4b70-410a-4277-bd15-f968ae7e75fd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 2]\n",
            " [0 8]]\n",
            "[0] [0] [0] [0] [1] [1] [1] [1] [0] [0] [0] [0] [1] [1] [1] [1] [0]\n",
            "         Metric     Value\n",
            "0            TP  8.000000\n",
            "1            TN  7.000000\n",
            "2            FP  2.000000\n",
            "3            FN  0.000000\n",
            "4           MSE  0.117647\n",
            "5          RMSE  0.342997\n",
            "6    Prevalence  0.590000\n",
            "7      Accuracy  0.882400\n",
            "8   Sensitivity  1.000000\n",
            "9   Specificity  0.777778\n",
            "10    Precision  0.800000\n",
            "11          NPV  1.000000\n",
            "12          FDR  0.200000\n",
            "13          FOR  0.000000\n",
            "14    check_Pos  1.000000\n",
            "15    check_Neg  1.000000\n",
            "16       Recall  1.000000\n",
            "17          FPR  0.222200\n",
            "18          FNR  0.000000\n",
            "19          TNR  0.777800\n",
            "20   check_Pos2  1.000000\n",
            "21   check_Neg2  1.000000\n",
            "22          LR+  4.500500\n",
            "23          LR-  0.000000\n",
            "24           F1  0.888900\n",
            "25        FBeta  0.822700\n",
            "26          MCC  0.788800\n",
            "27           BM  0.777800\n",
            "28           MK  0.800000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test_type,predictions9))\n",
        "\n",
        "import sklearn.metrics\n",
        "import math\n",
        "def matrix_metrix(y_test,test_predictions,beta):\n",
        "   CM = confusion_matrix(y_test_type,predictions9)\n",
        "   TN = CM[0][0]\n",
        "   FN = CM[1][0]\n",
        "   TP = CM[1][1]\n",
        "   FP = CM[0][1]\n",
        "   MSE = mean_squared_error(y_test_type,predictions9)\n",
        "   RMSE = np.sqrt(mean_squared_error(y_test_type,predictions9))\n",
        "   Population = TN+FN+TP+FP\n",
        "   Prevalence = round( (TP+FP) / Population,2)\n",
        "   Accuracy   = round( (TP+TN) / Population,4)\n",
        "   Sensitivity   = ( TP / (TP+FN))\n",
        "   Specificity   = ( TN / (TN+FP))\n",
        "   Precision  = round( TP / (TP+FP),4 )\n",
        "   NPV        = round( TN / (TN+FN),4 )\n",
        "   FDR        = round( FP / (TP+FP),4 )\n",
        "   FOR        = round( FN / (TN+FN),4 )\n",
        "   check_Pos  = Precision + FDR\n",
        "   check_Neg  = NPV + FOR\n",
        "   Recall     = round( TP / (TP+FN),4 )\n",
        "   FPR        = round( FP / (TN+FP),4 )\n",
        "   FNR        = round( FN / (TP+FN),4 )\n",
        "   TNR        = round( TN / (TN+FP),4 )\n",
        "   check_Pos2 = Recall + FNR\n",
        "   check_Neg2 = FPR + TNR\n",
        "   LRPos      = round( Recall/FPR,4 )\n",
        "   LRNeg      = round( FNR / TNR ,4 )\n",
        "   F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)\n",
        "   FBeta      = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)\n",
        "   MCC        = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)\n",
        "   BM         = Recall+TNR-1\n",
        "   MK         = Precision+NPV-1\n",
        "   mat_met = pd.DataFrame({\n",
        "'Metric':['TP','TN','FP','FN','MSE','RMSE','Prevalence','Accuracy','Sensitivity','Specificity','Precision','NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','F1','FBeta','MCC','BM','MK'],     'Value':[TP,TN,FP,FN,MSE,RMSE,Prevalence,Accuracy,Sensitivity,Specificity,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,F1,FBeta,MCC,BM,MK]})\n",
        "   return (mat_met)\n",
        "beta = 0.4\n",
        "mat_met = matrix_metrix(y_test_type,predictions9,beta)\n",
        "y_test_type = (y_test > 0.5).astype(int)\n",
        "print(*y_test_type)\n",
        "print (mat_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voOCbUm8-gxv",
        "outputId": "55ea1d5a-7f1f-44af-ec21-3803976d83b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 2]\n",
            " [0 8]]\n",
            "[0] [0] [0] [0] [1] [1] [1] [1] [0] [0] [0] [0] [1] [1] [1] [1] [0]\n",
            "         Metric     Value\n",
            "0            TP  8.000000\n",
            "1            TN  7.000000\n",
            "2            FP  2.000000\n",
            "3            FN  0.000000\n",
            "4           MSE  0.117647\n",
            "5          RMSE  0.342997\n",
            "6    Prevalence  0.590000\n",
            "7      Accuracy  0.882400\n",
            "8   Sensitivity  1.000000\n",
            "9   Specificity  0.777778\n",
            "10    Precision  0.800000\n",
            "11          NPV  1.000000\n",
            "12          FDR  0.200000\n",
            "13          FOR  0.000000\n",
            "14    check_Pos  1.000000\n",
            "15    check_Neg  1.000000\n",
            "16       Recall  1.000000\n",
            "17          FPR  0.222200\n",
            "18          FNR  0.000000\n",
            "19          TNR  0.777800\n",
            "20   check_Pos2  1.000000\n",
            "21   check_Neg2  1.000000\n",
            "22          LR+  4.500500\n",
            "23          LR-  0.000000\n",
            "24           F1  0.888900\n",
            "25        FBeta  0.822700\n",
            "26          MCC  0.788800\n",
            "27           BM  0.777800\n",
            "28           MK  0.800000\n"
          ]
        }
      ]
    }
  ]
}